<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Research Lab Simulator - Project Report</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.3);
            overflow: hidden;
        }
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }
        .content {
            padding: 40px;
        }
        h2 {
            color: #667eea;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 2em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        h3 {
            color: #764ba2;
            margin-top: 20px;
            margin-bottom: 10px;
            font-size: 1.5em;
        }
        h4 {
            color: #555;
            margin-top: 15px;
            margin-bottom: 8px;
            font-size: 1.2em;
        }
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        ul, ol {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        li {
            margin-bottom: 8px;
        }
        .code-block {
            background: #f4f4f4;
            border-left: 4px solid #667eea;
            padding: 15px;
            margin: 20px 0;
            overflow-x: auto;
            border-radius: 5px;
        }
        pre {
            margin: 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        .highlight {
            background: #fff3cd;
            padding: 2px 5px;
            border-radius: 3px;
        }
        .feature-box {
            background: #f8f9fa;
            border-left: 4px solid #764ba2;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }
        .architecture-diagram {
            background: #f8f9fa;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            font-family: monospace;
            overflow-x: auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background: #667eea;
            color: white;
        }
        tr:nth-child(even) {
            background: #f8f9fa;
        }
        .badge {
            display: inline-block;
            padding: 5px 10px;
            background: #667eea;
            color: white;
            border-radius: 15px;
            font-size: 0.85em;
            margin: 5px;
        }
        footer {
            background: #333;
            color: white;
            text-align: center;
            padding: 20px;
        }
        .metric {
            display: inline-block;
            margin: 10px 20px;
            text-align: center;
        }
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #667eea;
        }
        .metric-label {
            font-size: 0.9em;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ”¬ AI Research Lab Simulator</h1>
            <p>Multi-Agent LLM Research Pipeline using LangGraph</p>
            <p style="font-size: 0.9em; margin-top: 10px;">Project Report & Technical Documentation</p>
        </header>

        <div class="content">
            <h2>ğŸ“‹ Executive Summary</h2>
            <p>
                The <strong>AI Research Lab Simulator</strong> is a sophisticated multi-agent system that autonomously generates, 
                reviews, and refines research documents through collaborative AI agents. Built using <span class="highlight">LangGraph</span>, 
                <span class="highlight">LangChain</span>, <span class="highlight">Gemini 2.0 Flash</span>, and 
                <span class="highlight">Groq Mixtral</span>, the system demonstrates advanced concepts in autonomous agent coordination, 
                iterative refinement, and multi-LLM orchestration.
            </p>

            <div style="text-align: center; margin: 30px 0;">
                <div class="metric">
                    <div class="metric-value">5</div>
                    <div class="metric-label">Specialized Agents</div>
                </div>
                <div class="metric">
                    <div class="metric-value">2</div>
                    <div class="metric-label">LLM Providers</div>
                </div>
                <div class="metric">
                    <div class="metric-value">3</div>
                    <div class="metric-label">User Interfaces</div>
                </div>
                <div class="metric">
                    <div class="metric-value">6</div>
                    <div class="metric-label">Workflow Nodes</div>
                </div>
            </div>

            <h2>ğŸ¯ Project Objectives</h2>
            <ul>
                <li><strong>Autonomous Research Generation:</strong> Create a system where AI agents collaborate without human intervention</li>
                <li><strong>Multi-Agent Coordination:</strong> Implement decentralized decision-making through LangGraph state management</li>
                <li><strong>Iterative Refinement:</strong> Enable feedback loops for continuous quality improvement</li>
                <li><strong>Multi-LLM Integration:</strong> Leverage strengths of different models (Gemini for generation, Groq for evaluation)</li>
                <li><strong>Quality Assurance:</strong> Implement comprehensive validation through fact-checking, citation validation, and bias detection</li>
                <li><strong>Interactive Interfaces:</strong> Provide multiple ways to interact with the system and generated research</li>
            </ul>

            <h2>ğŸ—ï¸ System Architecture</h2>

            <h3>1. Core Components</h3>

            <h4>A. Multi-Agent System (5 Specialized Agents)</h4>
            <table>
                <tr>
                    <th>Agent</th>
                    <th>Model</th>
                    <th>Role</th>
                    <th>Output</th>
                </tr>
                <tr>
                    <td>ğŸ” Researcher</td>
                    <td>Gemini 2.0 Flash</td>
                    <td>Content Generation</td>
                    <td>Comprehensive research text</td>
                </tr>
                <tr>
                    <td>ğŸ“ Reviewer</td>
                    <td>Groq Mixtral</td>
                    <td>Quality Evaluation</td>
                    <td>Feedback + Quality Score (0-1)</td>
                </tr>
                <tr>
                    <td>âœï¸ Editor</td>
                    <td>Gemini 2.0 Flash</td>
                    <td>Content Refinement</td>
                    <td>Improved research text</td>
                </tr>
                <tr>
                    <td>âœ… Fact Checker</td>
                    <td>Groq Mixtral</td>
                    <td>Claim Verification</td>
                    <td>Verified/Flagged claims</td>
                </tr>
                <tr>
                    <td>ğŸ“š Citation Validator</td>
                    <td>Gemini 2.0 Flash</td>
                    <td>Source Validation</td>
                    <td>Citation analysis</td>
                </tr>
            </table>

            <h4>B. LangGraph Workflow</h4>
            <div class="architecture-diagram">
<pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LANGGRAPH WORKFLOW                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                         START
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   RESEARCH   â”‚ â† Researcher Agent
                    â”‚     NODE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    REVIEW    â”‚ â† Reviewer Agent
                    â”‚     NODE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  FACT CHECK  â”‚ â† Fact Checker Agent
                    â”‚     NODE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   CITATION   â”‚ â† Citation Validator
                    â”‚     NODE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    EDITOR    â”‚ â† Editor Agent
                    â”‚     NODE     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DECISION   â”‚
                    â”‚ should_continue? â”‚
                    â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
                       â”‚        â”‚
            quality < threshold â”‚ quality â‰¥ threshold
            OR iteration < max  â”‚ AND iteration â‰¥ max
                       â”‚        â”‚
                       â†“        â†“
                    REVIEW   FINALIZE
                    (LOOP)      â†“
                              END
</pre>
            </div>

            <h3>2. Technical Implementation</h3>

            <h4>A. State Management (LangGraph StateGraph)</h4>
            <div class="code-block">
<pre>
from typing import TypedDict, List, Dict, Annotated
import operator

class ResearchState(TypedDict):
    topic: str
    research_content: str
    review_feedback: str
    fact_check_results: str
    citation_results: str
    quality_score: float
    iteration: int
    agent_messages: Annotated[List[Dict], operator.add]
    final_document: str
</pre>
            </div>

            <h4>B. Agent Base Class</h4>
            <div class="code-block">
<pre>
class BaseAgent:
    def __init__(self, name: str, role: str, model, system_prompt: str):
        self.name = name
        self.role = role
        self.model = model
        self.system_prompt = system_prompt
        self.memory: List[Dict] = []
    
    def invoke(self, input_text: str, context: Dict = None) -> str:
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=input_text)
        ]
        response = self.model.invoke(messages)
        self.memory.append({
            "input": input_text,
            "output": response.content,
            "context": context
        })
        return response.content
</pre>
            </div>

            <h4>C. Workflow Graph Creation</h4>
            <div class="code-block">
<pre>
def create_research_workflow(agents):
    workflow = StateGraph(ResearchState)
    
    # Add nodes
    workflow.add_node("research", lambda s: research_node(s, agents))
    workflow.add_node("review", lambda s: review_node(s, agents))
    workflow.add_node("fact_check", lambda s: fact_check_node(s, agents))
    workflow.add_node("citation", lambda s: citation_node(s, agents))
    workflow.add_node("editor", lambda s: editor_node(s, agents))
    workflow.add_node("finalize", lambda s: finalize_node(s, agents))
    
    # Define flow
    workflow.set_entry_point("research")
    workflow.add_edge("research", "review")
    workflow.add_edge("review", "fact_check")
    workflow.add_edge("fact_check", "citation")
    workflow.add_edge("citation", "editor")
    
    # Conditional routing (iterative loop)
    workflow.add_conditional_edges(
        "editor",
        should_continue,
        {
            "continue": "review",
            "finalize": "finalize"
        }
    )
    
    workflow.add_edge("finalize", END)
    return workflow.compile()
</pre>
            </div>

            <h4>D. Convergence Logic</h4>
            <div class="code-block">
<pre>
def should_continue(state: ResearchState) -> str:
    if state["iteration"] >= MAX_ITERATIONS:
        return "finalize"
    if state.get("quality_score", 0) >= CONVERGENCE_THRESHOLD:
        return "finalize"
    return "continue"
</pre>
            </div>

            <h3>3. Research Tools & Validation</h3>

            <div class="feature-box">
                <h4>ğŸ” Knowledge Retrieval</h4>
                <p>LLM-based information gathering using Gemini's built-in knowledge base. No external web scraping required.</p>
            </div>

            <div class="feature-box">
                <h4>ğŸ“Š Quality Metrics (4-Dimensional Scoring)</h4>
                <ul>
                    <li><strong>Accuracy:</strong> Verified vs flagged claims (35% weight)</li>
                    <li><strong>Coherence:</strong> Sentence structure + vocabulary diversity (25% weight)</li>
                    <li><strong>Completeness:</strong> Required sections coverage (25% weight)</li>
                    <li><strong>Depth:</strong> Content length and detail (15% weight)</li>
                </ul>
            </div>

            <div class="feature-box">
                <h4>ğŸ›¡ï¸ Bias Detection</h4>
                <p>Identifies biased language patterns and contradictions in research text.</p>
            </div>

            <div class="feature-box">
                <h4>âœ… Fact Validation</h4>
                <p>Extracts claims and cross-references for consistency and evidence quality.</p>
            </div>

            <div class="feature-box">
                <h4>ğŸ“š Citation Tracking</h4>
                <p>Validates citation formats and tracks source provenance.</p>
            </div>

            <h2>ğŸ’» User Interfaces</h2>

            <h3>1. Research Dashboard (ui/app.py)</h3>
            <p><strong>Purpose:</strong> Generate research documents through automated multi-agent collaboration</p>
            <p><strong>Features:</strong></p>
            <ul>
                <li>3-tab layout: Dashboard, Agent Dialogue, Results, Workflow Graph</li>
                <li>Real-time metrics: Quality score, iterations, agent messages, word count</li>
                <li>Workflow controls: Start/Stop/Pause/Resume</li>
                <li>Parameter adjustment: Max iterations, convergence threshold, temperature</li>
                <li>âš¡ Fast Mode: 1 iteration, 0.6 threshold for quick results</li>
                <li>Live agent response streaming</li>
                <li>Process logging with timestamps</li>
            </ul>

            <h3>2. Research Chat (ui/research_chat.py)</h3>
            <p><strong>Purpose:</strong> Interactive Q&A about generated research documents</p>
            <p><strong>Features:</strong></p>
            <ul>
                <li>Generate research or upload existing documents</li>
                <li>Context-aware chat with any agent</li>
                <li>Quick actions: Summarize, Key Points, Questions, Improve</li>
                <li>Switch between agent perspectives</li>
                <li>Full chat history maintained</li>
            </ul>

            <h3>3. Agent Chat (ui/chat.py)</h3>
            <p><strong>Purpose:</strong> Direct conversation with individual agents</p>
            <p><strong>Features:</strong></p>
            <ul>
                <li>Select any agent for general-purpose chat</li>
                <li>No research context required</li>
                <li>Persistent chat history</li>
            </ul>

            <h2>ğŸ“¤ Export Capabilities</h2>
            <ol>
                <li><strong>Research Document (.txt):</strong> Clean research output</li>
                <li><strong>Full Report (.txt):</strong> Document + metadata + process logs</li>
                <li><strong>JSON Data (.json):</strong> Complete structured export with all agent messages</li>
                <li><strong>Process Logs (.txt):</strong> Timestamped execution timeline</li>
            </ol>

            <h2>âš¡ Performance Optimizations</h2>
            <table>
                <tr>
                    <th>Optimization</th>
                    <th>Implementation</th>
                    <th>Impact</th>
                </tr>
                <tr>
                    <td>Reduced Iterations</td>
                    <td>Default: 2 (was 5)</td>
                    <td>60% faster execution</td>
                </tr>
                <tr>
                    <td>Truncated Prompts</td>
                    <td>Max 500 chars context</td>
                    <td>Faster LLM processing</td>
                </tr>
                <tr>
                    <td>Higher Temperature</td>
                    <td>0.9 (was 0.7)</td>
                    <td>Faster generation</td>
                </tr>
                <tr>
                    <td>Fast Mode Toggle</td>
                    <td>1 iteration, 0.6 threshold</td>
                    <td>~15-20 seconds total</td>
                </tr>
                <tr>
                    <td>Streaming Responses</td>
                    <td>Real-time output display</td>
                    <td>Better UX, perceived speed</td>
                </tr>
            </table>

            <h2>ğŸ“ Project Structure</h2>
            <div class="code-block">
<pre>
fuck_it/
â”œâ”€â”€ agents/                  # Multi-agent system
â”‚   â”œâ”€â”€ base_agent.py       # Base class with memory
â”‚   â”œâ”€â”€ researcher.py       # Content generation
â”‚   â”œâ”€â”€ reviewer.py         # Quality evaluation
â”‚   â”œâ”€â”€ editor.py           # Content refinement
â”‚   â”œâ”€â”€ fact_checker.py     # Claim verification
â”‚   â”œâ”€â”€ citation_validator.py # Source validation
â”‚   â””â”€â”€ agent_factory.py    # Agent creation & distribution
â”‚
â”œâ”€â”€ config/                  # Configuration
â”‚   â”œâ”€â”€ settings.py         # Workflow parameters
â”‚   â”œâ”€â”€ models.py           # Model factory (Gemini/Groq)
â”‚   â””â”€â”€ speed_settings.py   # Performance tuning
â”‚
â”œâ”€â”€ tools/                   # Research & validation tools
â”‚   â”œâ”€â”€ search.py           # Knowledge retrieval
â”‚   â”œâ”€â”€ citation.py         # Citation tracking
â”‚   â”œâ”€â”€ quality_metrics.py  # 4D quality scoring
â”‚   â”œâ”€â”€ bias_detector.py    # Bias detection
â”‚   â”œâ”€â”€ fact_validator.py   # Fact validation
â”‚   â””â”€â”€ tool_manager.py     # Unified tool interface
â”‚
â”œâ”€â”€ workflow/                # LangGraph implementation
â”‚   â”œâ”€â”€ state.py            # StateGraph schema
â”‚   â”œâ”€â”€ nodes.py            # Workflow nodes (6 total)
â”‚   â”œâ”€â”€ graph.py            # Graph creation & routing
â”‚   â”œâ”€â”€ runner.py           # Workflow execution
â”‚   â””â”€â”€ visualizer.py       # Graph visualization
â”‚
â”œâ”€â”€ ui/                      # Streamlit interfaces
â”‚   â”œâ”€â”€ app.py              # Research dashboard
â”‚   â”œâ”€â”€ research_chat.py    # Interactive Q&A
â”‚   â””â”€â”€ chat.py             # Direct agent chat
â”‚
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ .env                     # API keys
â”œâ”€â”€ run.bat                  # Launch dashboard
â”œâ”€â”€ run_research_chat.bat    # Launch research chat
â”œâ”€â”€ run_chat.bat             # Launch agent chat
â””â”€â”€ visualize_graph.py       # Standalone visualization
</pre>
            </div>

            <h2>ğŸ”‘ Key Achievements</h2>
            <div style="display: flex; flex-wrap: wrap; gap: 10px; margin: 20px 0;">
                <span class="badge">Multi-Agent Collaboration</span>
                <span class="badge">LangGraph StateGraph</span>
                <span class="badge">Iterative Refinement</span>
                <span class="badge">Multi-LLM Integration</span>
                <span class="badge">Quality Metrics</span>
                <span class="badge">Bias Detection</span>
                <span class="badge">Real-time Streaming</span>
                <span class="badge">Interactive Chat</span>
                <span class="badge">3 User Interfaces</span>
                <span class="badge">Export Formats</span>
                <span class="badge">Workflow Controls</span>
                <span class="badge">Fast Mode</span>
            </div>

            <h2>ğŸš€ Future Scope</h2>

            <h3>1. Enhanced Agent Capabilities</h3>
            <ul>
                <li><strong>Domain-Specific Agents:</strong> Medical, Legal, Technical research specialists</li>
                <li><strong>Multi-Language Support:</strong> Research generation in multiple languages</li>
                <li><strong>Image Analysis Agent:</strong> Process and analyze research images/charts</li>
                <li><strong>Data Analysis Agent:</strong> Statistical analysis and visualization</li>
            </ul>

            <h3>2. Advanced Workflow Features</h3>
            <ul>
                <li><strong>Parallel Agent Execution:</strong> Run independent agents simultaneously</li>
                <li><strong>Dynamic Agent Selection:</strong> Choose agents based on research topic</li>
                <li><strong>Custom Workflow Builder:</strong> User-defined agent sequences</li>
                <li><strong>Checkpoint & Resume:</strong> Save and restore workflow state</li>
            </ul>

            <h3>3. Knowledge Integration</h3>
            <ul>
                <li><strong>RAG Implementation:</strong> Vector database for document retrieval</li>
                <li><strong>Web Search Integration:</strong> Real-time information from search APIs</li>
                <li><strong>Academic Database Access:</strong> PubMed, arXiv, Google Scholar integration</li>
                <li><strong>Knowledge Graph:</strong> Build and query research knowledge graphs</li>
            </ul>

            <h3>4. Collaboration Features</h3>
            <ul>
                <li><strong>Multi-User Support:</strong> Team collaboration on research</li>
                <li><strong>Version Control:</strong> Track research document versions</li>
                <li><strong>Comment System:</strong> Annotate and discuss research sections</li>
                <li><strong>Approval Workflow:</strong> Human-in-the-loop validation</li>
            </ul>

            <h3>5. Quality Enhancements</h3>
            <ul>
                <li><strong>Plagiarism Detection:</strong> Check for duplicate content</li>
                <li><strong>Readability Scoring:</strong> Flesch-Kincaid, SMOG index</li>
                <li><strong>SEO Optimization:</strong> Keyword analysis and suggestions</li>
                <li><strong>Citation Format Conversion:</strong> APA, MLA, Chicago, IEEE</li>
            </ul>

            <h3>6. Advanced UI Features</h3>
            <ul>
                <li><strong>Rich Text Editor:</strong> In-app document editing</li>
                <li><strong>Diff Viewer:</strong> Compare research iterations</li>
                <li><strong>Analytics Dashboard:</strong> Usage statistics and insights</li>
                <li><strong>Mobile App:</strong> iOS/Android native applications</li>
            </ul>

            <h3>7. Integration & APIs</h3>
            <ul>
                <li><strong>REST API:</strong> Programmatic access to workflow</li>
                <li><strong>Webhook Support:</strong> Event notifications</li>
                <li><strong>Third-Party Integrations:</strong> Notion, Google Docs, Confluence</li>
                <li><strong>CLI Tool:</strong> Command-line interface for automation</li>
            </ul>

            <h3>8. Model Enhancements</h3>
            <ul>
                <li><strong>Fine-Tuned Models:</strong> Domain-specific model training</li>
                <li><strong>Model Comparison:</strong> A/B testing different LLMs</li>
                <li><strong>Cost Optimization:</strong> Smart model selection based on task</li>
                <li><strong>Local Model Support:</strong> Ollama, LLaMA integration</li>
            </ul>

            <h2>ğŸ“Š Technical Specifications</h2>
            <table>
                <tr>
                    <th>Component</th>
                    <th>Technology</th>
                    <th>Version</th>
                </tr>
                <tr>
                    <td>Orchestration Framework</td>
                    <td>LangGraph</td>
                    <td>0.0.62</td>
                </tr>
                <tr>
                    <td>LLM Framework</td>
                    <td>LangChain</td>
                    <td>0.1.0</td>
                </tr>
                <tr>
                    <td>Primary LLM</td>
                    <td>Google Gemini 2.0 Flash</td>
                    <td>Latest</td>
                </tr>
                <tr>
                    <td>Secondary LLM</td>
                    <td>Groq Mixtral 8x7B</td>
                    <td>Latest</td>
                </tr>
                <tr>
                    <td>UI Framework</td>
                    <td>Streamlit</td>
                    <td>1.29.0</td>
                </tr>
                <tr>
                    <td>Programming Language</td>
                    <td>Python</td>
                    <td>3.13.5</td>
                </tr>
            </table>

            <h2>ğŸ“ Learning Outcomes</h2>
            <ul>
                <li>Implemented <strong>LangGraph StateGraph</strong> for complex workflow orchestration</li>
                <li>Designed <strong>multi-agent systems</strong> with specialized roles and responsibilities</li>
                <li>Integrated <strong>multiple LLM providers</strong> (Gemini, Groq) in a single workflow</li>
                <li>Built <strong>iterative refinement loops</strong> with convergence criteria</li>
                <li>Created <strong>real-time streaming interfaces</strong> with Streamlit</li>
                <li>Implemented <strong>quality metrics</strong> and validation systems</li>
                <li>Developed <strong>context-aware chat systems</strong> for research interaction</li>
                <li>Optimized <strong>performance</strong> through prompt engineering and parameter tuning</li>
            </ul>

            <h2>ğŸ“ Conclusion</h2>
            <p>
                The <strong>AI Research Lab Simulator</strong> successfully demonstrates the power of multi-agent collaboration 
                in autonomous research generation. By leveraging LangGraph's state management and conditional routing, 
                the system achieves sophisticated agent coordination without centralized control. The integration of 
                multiple LLM providers (Gemini for generation, Groq for evaluation) showcases effective multi-model 
                orchestration.
            </p>
            <p>
                The project delivers three distinct user interfaces catering to different use cases: automated research 
                generation, interactive Q&A, and direct agent consultation. With comprehensive quality metrics, 
                validation tools, and export capabilities, the system provides a complete research workflow solution.
            </p>
            <p>
                Performance optimizations including reduced iterations, truncated prompts, and fast mode enable 
                practical real-world usage with execution times under 30 seconds. The modular architecture and 
                extensive future scope provide a solid foundation for continued development and enhancement.
            </p>

            <h2>ğŸ”— Quick Start</h2>
            <div class="code-block">
<pre>
# 1. Install dependencies
pip install -r requirements.txt

# 2. Create a .env file and configure API keys in .env
GOOGLE_API_KEY=your_gemini_key
GROQ_API_KEY=your_groq_key

# 3. Launch interfaces
streamlit run ui/app.py              # Research Dashboard
streamlit run ui/research_chat.py    # Research Chat
streamlit run ui/chat.py             # Agent Chat

</pre>
        <footer>
            <p><strong>AI Research Lab Simulator</strong> - Version 1.1.0</p>
            <p>Powered by LangGraph â€¢ LangChain â€¢ Gemini â€¢ Groq â€¢ Streamlit</p>
        </footer>
    </div>
</body>
</html>
